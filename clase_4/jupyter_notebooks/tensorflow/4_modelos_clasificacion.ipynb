{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGfZ771blhgk"
      },
      "source": [
        "# Arquitecturas aplicadas a clasificación de texto\n",
        "\n",
        "Utilizaremos el dataset 20 Newsgroups para probar los modelos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dvmO-ANtnKTv"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-30 19:37:39.652111: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import os, re, csv, math, codecs, logging\n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "from io import StringIO\n",
        "import pickle\n",
        "import gdown\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.metrics import F1Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BDB1L0M5m8ar"
      },
      "outputs": [],
      "source": [
        "# cargamos 20 Newsgroups\n",
        "newsgroups_train = fetch_20newsgroups(subset='train',remove=('headers', 'footers', 'quotes'))\n",
        "newsgroups_test = fetch_20newsgroups(subset='test',remove=('headers', 'footers', 'quotes'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8H0JHHsyKYRh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: command not found: wget\n",
            "unzip:  cannot find or open wiki-news-300d-1M.vec.zip, wiki-news-300d-1M.vec.zip.zip or wiki-news-300d-1M.vec.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "# descargamos los embeddings de palabras de Fasttext para inglés y descomprimimos el archivo.\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
        "!unzip wiki-news-300d-1M.vec.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "V6Q2psVeNaM4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading word embeddings...\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'wiki-news-300d-1M.vec'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mloading word embeddings...\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m embeddings_index = {}\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m f = \u001b[43mcodecs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mwiki-news-300d-1M.vec\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f:\n\u001b[32m      7\u001b[39m     values = line.rstrip().rsplit(\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen codecs>:918\u001b[39m, in \u001b[36mopen\u001b[39m\u001b[34m(filename, mode, encoding, errors, buffering)\u001b[39m\n",
            "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'wiki-news-300d-1M.vec'"
          ]
        }
      ],
      "source": [
        "# cargamos los embeddings de palabras\n",
        "print('loading word embeddings...')\n",
        "embeddings_index = {}\n",
        "f = codecs.open('wiki-news-300d-1M.vec', encoding='utf-8')\n",
        "\n",
        "for line in f:\n",
        "    values = line.rstrip().rsplit(' ')\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('found %s word vectors' % len(embeddings_index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6PVbAh-fnP4E"
      },
      "outputs": [],
      "source": [
        "print(newsgroups_train.data[16])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRBZtI2zoTT7"
      },
      "outputs": [],
      "source": [
        "# instanciamos el tokenizador\n",
        "token = Tokenizer(num_words=30000,\n",
        "                filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
        "                lower=True,\n",
        "                split=' ',\n",
        "                char_level=False,\n",
        "                oov_token=\"UNK\",\n",
        "                document_count=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ClA5L6pnpHP7"
      },
      "outputs": [],
      "source": [
        "# fiteamos el tokenizador\n",
        "token.fit_on_texts(newsgroups_train.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "reverse_dictionary = token.index_word\n",
        "dictionary = dict([(value, key) for (key, value) in reverse_dictionary.items()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUgV6okQN_op"
      },
      "outputs": [],
      "source": [
        "# cargamos en una matriz los embeddings de las palabras\n",
        "# presentes en el vocabulario\n",
        "embed_dim=300\n",
        "num_words=len(dictionary)+1\n",
        "embedding_matrix=np.zeros([num_words,embed_dim])\n",
        "for word, idx in dictionary.items():\n",
        "  if idx <= num_words and word in embeddings_index:\n",
        "    embedding_matrix[idx,:]=embeddings_index[word]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1Wcf-ifpjjM"
      },
      "outputs": [],
      "source": [
        "# se tokenizan los textos\n",
        "train_sequences=token.texts_to_sequences(newsgroups_train.data)\n",
        "test_sequences=token.texts_to_sequences(newsgroups_test.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2toIg26nN8d7"
      },
      "outputs": [],
      "source": [
        "train_sequences[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oaqzg4Ayp-r"
      },
      "outputs": [],
      "source": [
        "embedding_matrix.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zhu1qis2PdXW"
      },
      "source": [
        "En este punto seleccionamos el tamaño de contexto a procesar en la variable `max_len`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEiPTqOBT_V7"
      },
      "outputs": [],
      "source": [
        "max_len=500\n",
        "train_sequences=pad_sequences(train_sequences,maxlen=max_len)\n",
        "test_sequences=pad_sequences(test_sequences,maxlen=max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJlUrLkfsBfK"
      },
      "outputs": [],
      "source": [
        "train_sequences[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWNt5zTlqZv9"
      },
      "outputs": [],
      "source": [
        "dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gmflnp5NQF8g"
      },
      "outputs": [],
      "source": [
        "token.index_word"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87VkHIk0idn2"
      },
      "source": [
        "# Suma de embeddings + MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGsJgyDDiicu"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'clip_to_image_size' from 'keras.src.layers.preprocessing.image_preprocessing.bounding_boxes.converters' (/opt/anaconda3/envs/venv312/lib/python3.12/site-packages/keras/src/layers/preprocessing/image_preprocessing/bounding_boxes/converters.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequential, Model\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m optimizers\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mK\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/venv312/lib/python3.12/site-packages/keras/_tf_keras/keras/__init__.py:29\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m visualization\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m wrappers\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_tf_keras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_tf_keras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layers\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_tf_keras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m losses\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/venv312/lib/python3.12/site-packages/keras/_tf_keras/__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_tf_keras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/venv312/lib/python3.12/site-packages/keras/_tf_keras/keras/__init__.py:30\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m wrappers\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_tf_keras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_tf_keras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layers\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_tf_keras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m losses\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_tf_keras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m metrics\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/venv312/lib/python3.12/site-packages/keras/_tf_keras/keras/layers/__init__.py:194\u001b[39m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage_preprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrandom_hue\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    189\u001b[39m     RandomHue,\n\u001b[32m    190\u001b[39m )\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage_preprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrandom_invert\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    192\u001b[39m     RandomInvert,\n\u001b[32m    193\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage_preprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrandom_perspective\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    195\u001b[39m     RandomPerspective,\n\u001b[32m    196\u001b[39m )\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage_preprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrandom_posterization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    198\u001b[39m     RandomPosterization,\n\u001b[32m    199\u001b[39m )\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage_preprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrandom_rotation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    201\u001b[39m     RandomRotation,\n\u001b[32m    202\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/venv312/lib/python3.12/site-packages/keras/src/layers/preprocessing/image_preprocessing/random_perspective.py:5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras_export\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage_preprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase_image_preprocessing_layer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[32m      3\u001b[39m     BaseImagePreprocessingLayer,\n\u001b[32m      4\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage_preprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbounding_boxes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconverters\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[32m      6\u001b[39m     clip_to_image_size,\n\u001b[32m      7\u001b[39m )\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage_preprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbounding_boxes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconverters\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[32m      9\u001b[39m     convert_format,\n\u001b[32m     10\u001b[39m )\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrandom\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mseed_generator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SeedGenerator\n",
            "\u001b[31mImportError\u001b[39m: cannot import name 'clip_to_image_size' from 'keras.src.layers.preprocessing.image_preprocessing.bounding_boxes.converters' (/opt/anaconda3/envs/venv312/lib/python3.12/site-packages/keras/src/layers/preprocessing/image_preprocessing/bounding_boxes/converters.py)"
          ]
        }
      ],
      "source": [
        "from keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D,\\\n",
        "                         Dropout, Dense, Lambda, Concatenate, Input\n",
        "from keras.models import Sequential, Model\n",
        "from keras import optimizers\n",
        "import tensorflow.keras.backend as K\n",
        "import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'clip_to_image_size' from 'keras.src.layers.preprocessing.image_preprocessing.bounding_boxes.converters' (/opt/anaconda3/envs/venv312/lib/python3.12/site-packages/keras/src/layers/preprocessing/image_preprocessing/bounding_boxes/converters.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
            "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 6\u001b[39m\n",
            "\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n",
            "\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n",
            "\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m one_hot, Tokenizer\n",
            "\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pad_sequences\n",
            "\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequential, Model\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/venv312/lib/python3.12/site-packages/keras/_tf_keras/keras/__init__.py:29\u001b[39m\n",
            "\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m visualization\n",
            "\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m wrappers\n",
            "\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_tf_keras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m backend\n",
            "\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_tf_keras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layers\n",
            "\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_tf_keras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m losses\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/venv312/lib/python3.12/site-packages/keras/_tf_keras/__init__.py:1\u001b[39m\n",
            "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_tf_keras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/venv312/lib/python3.12/site-packages/keras/_tf_keras/keras/__init__.py:30\u001b[39m\n",
            "\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m wrappers\n",
            "\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_tf_keras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m backend\n",
            "\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_tf_keras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layers\n",
            "\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_tf_keras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m losses\n",
            "\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_tf_keras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m metrics\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/venv312/lib/python3.12/site-packages/keras/_tf_keras/keras/layers/__init__.py:194\u001b[39m\n",
            "\u001b[32m    188\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage_preprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrandom_hue\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n",
            "\u001b[32m    189\u001b[39m     RandomHue,\n",
            "\u001b[32m    190\u001b[39m )\n",
            "\u001b[32m    191\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage_preprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrandom_invert\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n",
            "\u001b[32m    192\u001b[39m     RandomInvert,\n",
            "\u001b[32m    193\u001b[39m )\n",
            "\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage_preprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrandom_perspective\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n",
            "\u001b[32m    195\u001b[39m     RandomPerspective,\n",
            "\u001b[32m    196\u001b[39m )\n",
            "\u001b[32m    197\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage_preprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrandom_posterization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n",
            "\u001b[32m    198\u001b[39m     RandomPosterization,\n",
            "\u001b[32m    199\u001b[39m )\n",
            "\u001b[32m    200\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage_preprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrandom_rotation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n",
            "\u001b[32m    201\u001b[39m     RandomRotation,\n",
            "\u001b[32m    202\u001b[39m )\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/venv312/lib/python3.12/site-packages/keras/src/layers/preprocessing/image_preprocessing/random_perspective.py:5\u001b[39m\n",
            "\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras_export\n",
            "\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage_preprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase_image_preprocessing_layer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n",
            "\u001b[32m      3\u001b[39m     BaseImagePreprocessingLayer,\n",
            "\u001b[32m      4\u001b[39m )\n",
            "\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage_preprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbounding_boxes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconverters\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n",
            "\u001b[32m      6\u001b[39m     clip_to_image_size,\n",
            "\u001b[32m      7\u001b[39m )\n",
            "\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage_preprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbounding_boxes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconverters\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n",
            "\u001b[32m      9\u001b[39m     convert_format,\n",
            "\u001b[32m     10\u001b[39m )\n",
            "\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrandom\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mseed_generator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SeedGenerator\n",
            "\n",
            "\u001b[31mImportError\u001b[39m: cannot import name 'clip_to_image_size' from 'keras.src.layers.preprocessing.image_preprocessing.bounding_boxes.converters' (/opt/anaconda3/envs/venv312/lib/python3.12/site-packages/keras/src/layers/preprocessing/image_preprocessing/bounding_boxes/converters.py)"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import one_hot, Tokenizer\n",
        "from keras.utils import pad_sequences\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Activation, Dropout, Dense, Flatten, LSTM, GlobalMaxPooling1D, Embedding, Input, Concatenate, Bidirectional\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPLcPIS--Jgp"
      },
      "outputs": [],
      "source": [
        "\n",
        "class F1Callback(keras.callbacks.Callback):\n",
        "\n",
        "    '''\n",
        "    Este callback es una solución ad-hoc para calcular al final de cada epoch de\n",
        "    entrenamiento la métrica de Perplejidad sobre un conjunto de datos de validación.\n",
        "    La perplejidad es una métrica cuantitativa para evaluar la calidad de la generación de secuencias.\n",
        "    Además implementa la finalización del entrenamiento (Early Stopping)\n",
        "    si la perplejidad no mejora después de `patience` epochs.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, X_val,y_val,num_classes, history_f1, patience=5):\n",
        "      # El callback lo inicializamos con secuencias de validación sobre las cuales\n",
        "      # mediremos la perplejidad\n",
        "      self.X_val = X_val\n",
        "      self.y_val = y_val\n",
        "\n",
        "      self.max_score = 0\n",
        "      self.num_classes = num_classes\n",
        "      self.epsilon = 10E-8\n",
        "      self.patience = patience\n",
        "      self.patience_counter = 0\n",
        "\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "\n",
        "        predictions = self.model.predict(self.X_val,verbose=0)\n",
        "\n",
        "        y_pred = np.argmax(predictions,axis=1)\n",
        "\n",
        "        counter = np.zeros((self.num_classes,self.num_classes))\n",
        "\n",
        "        for idx_pred,idx_true in zip(y_pred,self.y_val):\n",
        "          counter[idx_pred,idx_true] += 1\n",
        "\n",
        "        # sea calcula TP, FN y FP\n",
        "        TP = np.diag(counter)\n",
        "        FN = counter.sum(axis=0)-TP\n",
        "        FP = counter.sum(axis=1)-TP\n",
        "\n",
        "        precision = TP/(TP+FP+self.epsilon)\n",
        "        recall = TP/(TP+FN+self.epsilon)\n",
        "\n",
        "        # se calcula el F1-sscore\n",
        "        f1 = 2*precision*recall/(precision+recall+self.epsilon)\n",
        "\n",
        "        current_score = np.mean(f1)\n",
        "\n",
        "        history_f1.append(current_score)\n",
        "\n",
        "        print(f'\\n f1 macro: {current_score} \\n')\n",
        "\n",
        "        # chequeamos si tenemos que  detener el entrenamiento\n",
        "        if current_score > self.max_score:\n",
        "          self.max_score = current_score\n",
        "          self.model.save(\"my_model.keras\")\n",
        "          print(\"Saved new model!\")\n",
        "          self.patience_counter = 0\n",
        "        else:\n",
        "          self.patience_counter += 1\n",
        "          if self.patience_counter == 5:\n",
        "            print(\"Stopping training...\")\n",
        "            self.model.stop_training = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlOr3GDayiAK"
      },
      "outputs": [],
      "source": [
        "nb_words=num_words\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(nb_words, embed_dim, weights=[embedding_matrix], input_length=max_len, trainable=False))\n",
        "model.add(Lambda(lambda x: K.sum(x, axis=1)))\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(20, activation='softmax'))  #multi-label (k-hot encoding)\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAhKga5rjAHG"
      },
      "outputs": [],
      "source": [
        "history_f1 = []\n",
        "model.fit(train_sequences, newsgroups_train.target,batch_size=64,epochs=40,callbacks=[F1Callback(test_sequences,newsgroups_test.target,20,history_f1)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnmjFl8T6jyr"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ane8TKiv6U9l"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Entrenamiento\n",
        "epoch_count = range(1, len(history_f1) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=history_f1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8QnWlpxyqzF"
      },
      "source": [
        "## Clasificador Embeddings + CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjoQz25NazxB"
      },
      "outputs": [],
      "source": [
        "nb_words=num_words\n",
        "num_filters=64\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(nb_words, embed_dim, weights=[embedding_matrix], input_length=max_len, trainable=False))\n",
        "\n",
        "model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n",
        "model.add(MaxPooling1D(2))\n",
        "\n",
        "model.add(Conv1D(num_filters*2, 7, activation='relu', padding='same'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(20, activation='softmax'))\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fnkm8psrbO3A"
      },
      "outputs": [],
      "source": [
        "history_f1 = []\n",
        "model.fit(train_sequences, newsgroups_train.target,batch_size=128,epochs=40,callbacks=[F1Callback(test_sequences,newsgroups_test.target,20,history_f1)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_G07HdAzwlr"
      },
      "source": [
        "## Clasificación con TextCNN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCaQWMIVdSiI"
      },
      "outputs": [],
      "source": [
        "\n",
        "nb_words=num_words\n",
        "num_filters=64\n",
        "\n",
        "input_layer = Input(shape=(max_len,))\n",
        "embedding_layer=Embedding(nb_words, embed_dim, weights=[embedding_matrix], input_length=max_len, trainable=False)(input_layer)\n",
        "\n",
        "conv4=Conv1D(num_filters, 4, activation='relu', padding='same')(embedding_layer)\n",
        "conv3=Conv1D(num_filters, 3, activation='relu', padding='same')(embedding_layer)\n",
        "conv2=Conv1D(num_filters, 2, activation='relu', padding='same')(embedding_layer)\n",
        "pool4=GlobalMaxPooling1D()(conv4)\n",
        "pool3=GlobalMaxPooling1D()(conv3)\n",
        "pool2=GlobalMaxPooling1D()(conv2)\n",
        "added = Concatenate()([pool4, pool3, pool2])\n",
        "\n",
        "dense1=Dense(32, activation='relu')(added)\n",
        "dense2=Dense(20, activation='softmax')(dense1)\n",
        "\n",
        "model=Model(input_layer , dense2)\n",
        "\n",
        "# adam = optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6YLe-vn1GX3"
      },
      "outputs": [],
      "source": [
        "\n",
        "history_f1 = []\n",
        "model.fit(train_sequences, newsgroups_train.target,batch_size=128,epochs=40,callbacks=[F1Callback(test_sequences,newsgroups_test.target,20,history_f1)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KTF5uIW7QAe"
      },
      "source": [
        "# MLP + Embeddings + Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqvbWeXlz-qP"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Dot,RepeatVector,TimeDistributed,Multiply,Lambda,Flatten,Activation,Reshape\n",
        "from keras.activations import softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9lQCd7N7Uwu"
      },
      "outputs": [],
      "source": [
        "\n",
        "def softMaxOverTime(x):\n",
        "    return softmax(x,axis=1)\n",
        "\n",
        "key_dim=50\n",
        "nb_words=num_words\n",
        "num_filters=64\n",
        "\n",
        "input_layer = Input(shape=(max_len,))\n",
        "embedding_layer = Embedding(nb_words, embed_dim, weights=[embedding_matrix], input_length=max_len, trainable=False)(input_layer)\n",
        "\n",
        "dense_input = Dense(key_dim, activation=\"tanh\")(embedding_layer)\n",
        "ulog_attention = Dense(1,activation=\"linear\")(dense_input)\n",
        "\n",
        "attention = Activation(softMaxOverTime)(ulog_attention)\n",
        "\n",
        "repeated_attention = TimeDistributed(RepeatVector(embed_dim))(attention)\n",
        "\n",
        "repeated_attention = Reshape([max_len,embed_dim])(repeated_attention)\n",
        "\n",
        "weighted_embeddings = Multiply()([repeated_attention,embedding_layer])\n",
        "embedding_sum = Lambda(lambda x: K.sum(x, axis=1),output_shape=(300,))(weighted_embeddings)\n",
        "\n",
        "dense1=Dense(32, activation='relu')(embedding_sum)\n",
        "dense2=Dense(20, activation='softmax')(dense1)\n",
        "\n",
        "model=Model(input_layer , dense2)\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_6eY80XIe48"
      },
      "outputs": [],
      "source": [
        "history_f1 = []\n",
        "model.fit(train_sequences, newsgroups_train.target,batch_size=128,epochs=40,callbacks=[F1Callback(test_sequences,newsgroups_test.target,20,history_f1)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEucYPxZJMCk"
      },
      "source": [
        "# MLP + Embeddings + Attention + CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkvAI3wcJRmX"
      },
      "outputs": [],
      "source": [
        "\n",
        "value_dim=100\n",
        "\n",
        "def softMaxOverTime(x):\n",
        "    return softmax(x,axis=1)\n",
        "\n",
        "\n",
        "nb_words=num_words\n",
        "num_filters=64\n",
        "\n",
        "input_layer = Input(shape=(max_len,))\n",
        "embedding_layer=Embedding(nb_words, embed_dim, weights=[embedding_matrix], input_length=max_len, trainable=False)(input_layer)\n",
        "\n",
        "conv_out=Conv1D(value_dim,8,padding=\"same\")(embedding_layer)\n",
        "conv_out=Activation(\"relu\")(conv_out)\n",
        "#conv_out=Conv1D(value_dim,8,activation=\"relu\",padding=\"same\")(conv_out)\n",
        "conv_out=Conv1D(value_dim,8,activation=\"tanh\",padding=\"same\")(conv_out)\n",
        "\n",
        "ulog_attention=Dense(1,activation=\"linear\")(conv_out)\n",
        "attention=Activation(softMaxOverTime)(ulog_attention)\n",
        "repeated_attention=TimeDistributed(RepeatVector(value_dim))(attention)\n",
        "repeated_attention=Reshape([max_len,value_dim])(repeated_attention)\n",
        "weighted_embeddings=Multiply()([repeated_attention,conv_out])\n",
        "embedding_sum = Lambda(lambda x: K.sum(x, axis=1),output_shape=(100,))(weighted_embeddings)\n",
        "\n",
        "dense1=Dense(100, activation='relu')(embedding_sum)\n",
        "dense2=Dense(20, activation='softmax')(dense1)\n",
        "\n",
        "model=Model(input_layer , dense2)\n",
        "\n",
        "# adam = optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxm9Eu3rJ4gs"
      },
      "outputs": [],
      "source": [
        "history_f1 = []\n",
        "model.fit(train_sequences, newsgroups_train.target,batch_size=128,epochs=40,callbacks=[F1Callback(test_sequences,newsgroups_test.target,20,history_f1)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLHo1NKmMe3S"
      },
      "source": [
        "# Bidir RNN + Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcOrcMWzMhoW"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'num_words' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msoftMaxOverTime\u001b[39m(x):\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m softmax(x,axis=\u001b[32m1\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m nb_words=\u001b[43mnum_words\u001b[49m\n\u001b[32m      9\u001b[39m num_filters=\u001b[32m64\u001b[39m\n\u001b[32m     11\u001b[39m input_layer = Input(shape=(max_len,))\n",
            "\u001b[31mNameError\u001b[39m: name 'num_words' is not defined"
          ]
        }
      ],
      "source": [
        "from keras.layers import Bidirectional, LSTM\n",
        "\n",
        "value_dim=100\n",
        "\n",
        "def softMaxOverTime(x):\n",
        "    return softmax(x,axis=1)\n",
        "\n",
        "nb_words=num_words\n",
        "num_filters=64\n",
        "\n",
        "input_layer = Input(shape=(max_len,))\n",
        "embedding_layer=Embedding(nb_words, embed_dim, weights=[embedding_matrix], input_length=max_len, trainable=False)(input_layer)\n",
        "# lstm_out=Bidirectional(LSTM(value_dim, return_sequences=True))(embedding_layer)\n",
        "# lstm_out=Bidirectional(LSTM(value_dim, return_sequences=True))(lstm_out)\n",
        "lstm_out=Bidirectional(LSTM(value_dim, return_sequences=True,activation=\"relu\"),merge_mode=\"sum\")(embedding_layer)\n",
        "\n",
        "ulog_attention=Dense(1,activation=\"linear\")(lstm_out)\n",
        "attention=Activation(softMaxOverTime)(ulog_attention)\n",
        "repeated_attention=TimeDistributed(RepeatVector(value_dim))(attention)\n",
        "repeated_attention=Reshape([max_len,value_dim])(repeated_attention)\n",
        "weighted_embeddings=Multiply()([repeated_attention,lstm_out])\n",
        "embedding_sum = Lambda(lambda x: K.sum(x, axis=1),output_shape=(None,value_dim))(weighted_embeddings)\n",
        "\n",
        "dense1=Dense(100, activation='relu')(embedding_sum)\n",
        "dense2=Dense(20, activation='softmax')(dense1)\n",
        "\n",
        "model=Model(input_layer , dense2)\n",
        "\n",
        "# adam = optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=\"rmsprop\", metrics=['accuracy'])\n",
        "# model.compile(loss='sparse_categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88dnPOJVNrLS"
      },
      "outputs": [],
      "source": [
        "history_f1 = []\n",
        "model.fit(train_sequences, newsgroups_train.target,batch_size=128,epochs=40,callbacks=[F1Callback(test_sequences,newsgroups_test.target,20,history_f1)])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv312",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
